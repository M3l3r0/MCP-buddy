<div align="center">

# ğŸ¤– MCPbuddy

### *AI orchestrator for multiple MCP servers*

[![Node.js](https://img.shields.io/badge/Node.js-18+-339933?style=for-the-badge&logo=node.js&logoColor=white)](https://nodejs.org/)
[![React](https://img.shields.io/badge/React-18.2-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](LICENSE)

**Chat interface with AI that automatically decides which MCP servers and tools to use**

</div>

---

## ğŸš€ Quick Start

```bash
git clone https://github.com/M3l3r0/MCP-buddy.git
cd MCP-buddy
npm install
npm run dev
```

**Open**: http://localhost:3000

---

## ğŸ¯ What is it?

MCPbuddy connects to multiple **MCP (Model Context Protocol) servers**. When you ask a question, an **LLM intelligently decides** which servers and tools to query, then synthesizes all responses into one answer.

**Think**: ChatGPT interface + your MCP servers + AI orchestration

---

## âœ¨ Key Features

### ğŸ­ AI Orchestration
Ask anything â†’ LLM picks the right servers/tools â†’ Executes in parallel â†’ One coherent answer

### ğŸ’¬ Modern Chat
- âš¡ ChatGPT-style typing animation
- ğŸ’¾ Persistent conversation history
- ğŸ·ï¸ Auto-titles from first message

### ğŸ”Œ Multi-Server
- Connect multiple MCP servers
- Works with Snowflake, custom APIs, any MCP-compatible endpoint
- Multiple auth methods: Bearer, API Key, OAuth, Basic

### ğŸ¤– LLM Support
Snowflake Cortex â€¢ OpenAI â€¢ Anthropic â€¢ Ollama â€¢ Custom APIs

---

## âš™ï¸ Setup

### 1. Add Servers

**UI**: `âš™ï¸ Servers` â†’ `+ Add Server`

```
Name: My Server
URL: https://your-mcp-endpoint.com/...
Auth: Bearer Token
Token: your-token-here
```

### 2. Configure LLM (Optional)

**UI**: `ğŸ¤– LLM Config` â†’ `+ Add LLM Config`

```
Provider: Snowflake / OpenAI / Anthropic / Ollama
Model: llama3-70b / gpt-4 / claude-3-5-sonnet
API Key: your-key
```

### 3. Chat!

**Without LLM**: Select one server, get raw responses  
**With LLM**: 
- One server = AI-enhanced responses
- Multiple servers = ğŸ­ **Orchestration mode** (AI picks servers automatically)

---

## ğŸ­ How Orchestration Works

```
Your Question
    â†“
ğŸ§  LLM analyzes â†’ Decides which servers/tools
    â†“
âš¡ Executes in parallel
    â†“
ğŸ¨ LLM combines results
    â†“
ğŸ’¬ Single answer
```

**Example**: *"Tell me about X and Y"* â†’ AI queries relevant servers â†’ Synthesized response

---

## ğŸ“Š What You See

- ğŸ’¬ **Chat messages** with smooth typing animation
- ğŸ“ˆ **Real-time logs** of every server call
- â±ï¸ **Performance metrics** (MCP time, LLM time, total)
- ğŸ” **Expandable details** in each message

---

## ğŸ› ï¸ Stack

React â€¢ TypeScript â€¢ Node.js â€¢ Express â€¢ Tailwind â€¢ Vite

---

## ğŸ› Troubleshooting

**Server not responding?**
- Check URL and token validity
- Verify MCP server is running

**AI not working?**
- Toggle `AI: ON` (green button)
- Check LLM API key

**No orchestration?**
- Need **LLM enabled** + **multiple servers enabled**

---

## ğŸ” Security

- âœ… No hardcoded credentials
- âœ… Local storage only
- âœ… Git-ignores secrets (`*.env`, `*credentials*`, `*-local.json`)

**Never commit API keys or tokens!**

---

## ğŸ“š Docs

- [Configuration Examples](docs/CONFIG_EXAMPLE.md)
- [Quick Start Guide](docs/QUICKSTART.md)
- [Security Policy](docs/SECURITY.md)
- [Changelog](CHANGELOG.md)

**External**:
[MCP Protocol](https://modelcontextprotocol.io/) â€¢ [Snowflake Cortex](https://docs.snowflake.com/en/user-guide/snowflake-cortex) â€¢ [OpenAI](https://platform.openai.com/docs)

---

## ğŸ“„ License

MIT - see [LICENSE](LICENSE)

---

<div align="center">

**Made with â¤ï¸ by [@M3l3r0](https://github.com/M3l3r0)**

### â­ Star if useful!

[ğŸ› Report Bug](https://github.com/M3l3r0/MCP-buddy/issues) â€¢ [âœ¨ Request Feature](https://github.com/M3l3r0/MCP-buddy/issues)

</div>
